{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numexpr as en\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $$ H(X,Y) = - \\sum_{x \\in X} \\sum_{y \\in Y} P(x,y)logP(x,y) $$\n",
    "# 联合熵与信息熵的区别就是用联合概率替换边缘概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,0,1,1,0])\n",
    "Y = np.array([1,1,1,0,0])\n",
    "A,B = np.array([0,0]),np.array([1,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "def combinationL(loop_val): \n",
    "    return np.array(list({i for i in product(*loop_val)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumpyProb(X,symbol,x):\n",
    "    n = X.size\n",
    "    Lambda = \"{}{}{}\".format(\"X\",symbol,\"x\")\n",
    "    expr = en.evaluate(Lambda)\n",
    "    return (expr).dot(np.ones(n))/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([0.5, 0.5]), array([0.2, 0.2, 0.2, 0.4]))"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "def NumpyJointProb(X,Y):\n",
    "    init_XY = np.c_[X,Y]\n",
    "    distionXY = combinationL(init_XY.T)\n",
    "    m,n = init_XY.shape\n",
    "    dm,dn = distionXY.shape\n",
    "    if dm ==1:\n",
    "        distionXY = np.repeat(distionXY,dn,axis=0).T\n",
    "        return np.array([((init_XY.T==xy).dot(np.ones(n))==n).dot(np.ones(m))/m for xy in distionXY])\n",
    "    elif dm > 1:\n",
    "        return np.array([((init_XY==xy).dot(np.ones(n))==n).dot(np.ones(m))/m for xy in distionXY])\n",
    "\n",
    "NumpyJointProb(A,B),NumpyJointProb(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "def NumpyEntropy(X):\n",
    "    NE = 0\n",
    "    for x in np.unique(X):\n",
    "        PX = NumpyProb(X,'==',x)\n",
    "        NE += (- PX * np.log2(PX))\n",
    "    return NE\n",
    "NumpyEntropy(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1.9219280948873623, 1.0)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "def NumpyJointEntropy(X,Y):\n",
    "    PXY = NumpyJointProb(X,Y)\n",
    "    return (-PXY*np.log2(PXY)).sum()\n",
    "    \n",
    "NumpyJointEntropy(X,Y),NumpyJointEntropy(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-66c53067",
   "display_name": "PyCharm (InferenceSystem)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}