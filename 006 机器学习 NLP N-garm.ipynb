{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jieba \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = \"\"\"整体上差别不大，就是pytorch中dot只能针对一维数组，也就是shape为(m,)这样的矩阵，而如果是多维数组则需要使用mm，需要注意的是无论是numpy，cupy还是pytorch，矩阵的直接 “*”都是哈达玛积，也就是各位相乘不求和，而dot或者mm才是正常的矩阵相乘，也就是我们初高中熟悉的“正经”的矩阵乘法，需要注意。\n",
    "\n",
    "可以看到，torch和numpy之间的差异性很小，如果使用cuda，直接把数据.cuda()到gpu上，那么接下去的运算就都会自动在gpu上运行了，贼方便。\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([['整体', '上'],\n       ['上', '差别'],\n       ['差别', '不'],\n       ['不', '大'],\n       ['大', '就是'],\n       ['就是', 'pytorch'],\n       ['pytorch', '中'],\n       ['中', 'dot'],\n       ['dot', '只能'],\n       ['只能', '针对'],\n       ['针对', '一维'],\n       ['一维', '数组'],\n       ['数组', '也'],\n       ['也', '就是'],\n       ['就是', 'shape'],\n       ['shape', '为'],\n       ['为', 'm'],\n       ['m', '这样'],\n       ['这样', '的'],\n       ['的', '矩阵'],\n       ['矩阵', '而'],\n       ['而', '如果'],\n       ['如果', '是'],\n       ['是', '多维'],\n       ['多维', '数组'],\n       ['数组', '则'],\n       ['则', '需要'],\n       ['需要', '使用'],\n       ['使用', 'mm'],\n       ['mm', '需要'],\n       ['需要', '注意'],\n       ['注意', '的'],\n       ['的', '是'],\n       ['是', '无论是'],\n       ['无论是', 'numpy'],\n       ['numpy', 'cupy'],\n       ['cupy', '还是'],\n       ['还是', 'pytorch'],\n       ['pytorch', '矩阵'],\n       ['矩阵', '的'],\n       ['的', '直接'],\n       ['直接', '都'],\n       ['都', '是'],\n       ['是', '哈达'],\n       ['哈达', '玛积'],\n       ['玛积', '也'],\n       ['也', '就是'],\n       ['就是', '各位'],\n       ['各位', '相乘'],\n       ['相乘', '不'],\n       ['不', '求和'],\n       ['求和', '而'],\n       ['而', 'dot'],\n       ['dot', '或者'],\n       ['或者', 'mm']], dtype='<U7')"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "relambda = re.compile(r\"[^\\u4e00-\\u9fa5-\\^a-z^A-Z^0-9^，^。]\")\n",
    "strings = re.sub(relambda,\"\",page)\n",
    "tokenization = list(filter(lambda x : x not in ['，'],jieba.cut(strings)))\n",
    "\n",
    "def Ngarm(n=2):\n",
    "    math = __import__(\"math\")\n",
    "    return np.array([tokenization[i:i+2] for i in range(math.ceil(len(tokenization)/n))])\n",
    "Ngarm(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-66c53067",
   "display_name": "PyCharm (InferenceSystem)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}