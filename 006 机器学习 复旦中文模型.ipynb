{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 197k/144M [00:00<01:21, 1.77MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://212.129.155.247/fasthan/fasthan_base.zip not found in cache, downloading to /tmp/tmp0o9tq_p_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144M/144M [00:19<00:00, 7.54MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish download from http://212.129.155.247/fasthan/fasthan_base.zip\n",
      "Copy file to /home/manman/.fastNLP/fasthan/fasthan_base\n",
      "loading vocabulary file /home/manman/.fastNLP/fasthan/fasthan_base/vocab.txt\n",
      "Load pre-trained BERT parameters from file /home/manman/.fastNLP/fasthan/fasthan_base/model.bin.\n"
     ]
    }
   ],
   "source": [
    "from fastHan import FastHan\n",
    "model = FastHan(model_type='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target 参数可在 \n",
    "## {'Parsing'=依存分析、'CWS'=分词、'POS'=词性标注、'NER'=命名实体识} \n",
    "#### 四个选项中取值，模型将分别进行依存分析、分词、词性标注、命名实体识别任务,\n",
    "#### 模型默认进行 CWS 任务。其中词性标注任务包含了分词的信息，\n",
    "#### 而依存分析任务又包含了词性标注任务的信息。\n",
    "#### 命名实体识别任务相较其他任务独立。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['我', 2, 'top', 'PN'], ['是', 0, 'root', 'VC'], ['张', 2, 'attr', 'M'], ['慢慢', 2, 'advmod', 'AD']],\n",
       " [['我', 2, 'top', 'PN'], ['是', 0, 'root', 'VC'], ['张小伴', 5, 'assmod', 'NR'], ['的', 3, 'assm', 'DEG'], ['爸爸', 2, 'attr', 'NN']]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [\"我是张慢慢\",\"我是张小伴的爸爸\"]\n",
    "answer = model(sentence,target='Parsing')\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型的输出是在 fastHan 模块中定义的 sentence 与 token 类。\n",
    "#### 模型将输出一个由 sentence 组成的列表，而每个 sentence 又由 token 组成。每个 token 本身代表一个被分好的词，有 pos、head、head_label、ner 四项属性，代表了该词的词性、依存关系、命名实体识别信息。\n",
    "\n",
    "#### 如果分别运行 CWS、POS、Parsing 任务，模型输出的分词结果等可能存在冲突。如果想获得不冲突的各类信息，可以直接运行包含全部所需信息的那项任务。\n",
    "\n",
    "#### 模型的 POS、Parsing 任务均使用 CTB 标签集。NER 使用 msra 标签集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型在 13 个语料库中进行训练，其中包含 10 个分词语料库。不同语料库的分词粒度均不同，如本模型默认的 CTB 语料库分词粒度较细。如果想切换不同的粒度，可以使用模型的 set_cws_style 函数，例子如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['一', '个', '苹果', '手机']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2 = '一个苹果手机'\n",
    "model(sentence2,target='CWS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.511 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['一个', '苹果', '手机']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(jieba.cut_for_search(sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['一个', '苹果', '手机']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_cws_style('cnc')\n",
    "model(sentence2,'CWS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['苹']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_cws_style('cnc')\n",
    "model._get_list(sentence2,tags='CWS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU 模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 繁體字分詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['今天', '天氣', '還', '不錯', '，', '要不', '我們', '出去', '走走', '怎麼樣', '？']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence3 = '今天天氣還不錯，要不我們出去走走怎麼樣？'\n",
    "model.set_cws_style('as')\n",
    "model(sentence3,target='CWS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['今天', '天氣', '還', '不錯', '，', '要不', '我們', '出去', '走走', '怎麼樣', '？']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_cws_style('cityu')\n",
    "model(sentence3,target='CWS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型在以下数据集进行测试和训练：\n",
    "\n",
    "## CWS：AS、CITYU、CNC、CTB、MSR、PKU、SXU、UDC、WTB、ZX\n",
    "\n",
    "## NER：MSRA、OntoNotes\n",
    "\n",
    "## POS & Parsing：CTB9\n",
    "\n",
    "### 注：模型在训练 NER OntoNotes 时将其标签集转换为与 MSRA 一致。\n",
    "\n",
    "## 最终模型在各项任务中取得的 F 值如下：\n",
    "<img src=\"/Users/manmanzhang/Library/Mobile Documents/com~apple~CloudDocs/MyProject/InferenceSystem/src/I5_algorithm/im/7FE7B1F4-0B20-4796-91C8-37818A69DFE6.png\n",
    "\">\n",
    "\n",
    "## 表格中单位为百分数。CWS 的成绩是 10 项任务的平均成绩。Parsing 中的两个成绩分别代表 F_{ldep} 和 F_{udep}。SOTA 模型的数据来自笔者对网上资料及论文的查阅，如有缺漏请指正，不胜感激。这五项 SOTA 表现分别来自如下五篇论文："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
