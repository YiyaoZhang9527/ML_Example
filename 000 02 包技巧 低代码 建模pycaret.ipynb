{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抢人饭碗了！推荐一款全自动的机器学习建模神器PyCaret\n",
    "#### https://mp.weixin.qq.com/s/i_qCCeY6RV1Me7g3k0SZOA\n",
    "1. 获取数据\n",
    "在本次循序渐进的教程中，我们将使用“糖尿病”数据集，目标是根据血压，胰岛素水平，年龄等多种因素来预测患者结果。直接从存储库导入数据集的最简单方法是使用pycaret.datasets模块中的get_data函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pycaret.datasets import get_data\n",
    "import pandas as pd\n",
    "diabetes = get_data('diabetes',save_copy=False, profile = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 搭建环境\n",
    "PyCaret中任何机器学习实验的第一步都是通过导入所需的模块并初始化setup()来设置环境的。本示例中使用的模块是pycaret.classification。导入模块后，将通过定义数据框（'diabetes'）和目标变量（'Class variable'）来初始化setup()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "exp1 = setup(diabetes, target = 'Class variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有预处理步骤都在setup()中应用。PyCaret拥有20多种功能，可为机器学习准备数据，它会根据setup函数中定义的参数创建转换管道（transformation pipeline）。\n",
    "它会自动编排管道（pipeline）中的所有依赖项，因此您不必手动管理对测试数据集或未知的数据集进行转换的顺序执行。PyCaret的管道可以轻松地在各种环境之间转移，以实现大规模运行或轻松部署到生产环境中。以下是PyCaret首次发布时可用的预处理功能。PyCaret的预处理能力如下图：\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \" /home/manman/Documents/相互转移/InferenceSystem/src/I5_algorithm/pycaret-setup.png\",width=(1920*0.3), height=(1080*0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.比较模型\n",
    "这是在有监督的机器学习实验（分类或回归）中建议的第一步。此功能训练模型库中的所有模型，并使用k倍交叉验证（默认10倍）比较通用评估指标。使用的评估指标是：\n",
    "\n",
    "分类：Accuracy（准确度），AUC，Recall（召回率），Precision（精确度），F1，Kappa\n",
    "\n",
    "回归：MAE，MSE，RMSE，R2，RMSLE，MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡特别提醒：\n",
    "默认情况下，使用10倍交叉验证来评估指标。可以通过更改fold参数的值来更改它。\n",
    "\n",
    "默认情况下，表格按“准确度”（从最高到最低）排序。可以通过更改sort参数的值来更改。\n",
    "# 4.创建模型\n",
    "在PyCaret的任何模块中创建模型就像编写create_model一样简单。它仅接受一个参数，即作为字符串输入传递的模型名称。此函数返回具有k倍交叉验证分数和训练有素的模型对象的表格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = create_model('ada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "变量“ adaboost”存储一个由create_model函数返回的经过训练的模型对象，该对象是scikit-learn评估器。可以通过在变量后使用点（.）来访问训练对象的原始属性。请参见下面的示例。\n",
    "特别提醒：ret具有60多个开源即用型（ready-to-use）算法。查看PyCaret中可用的估算器/模型的完整列表：https://www.pycaret.org/create-model\n",
    "# 5.调整模型\n",
    "tune_model功能用于机器学习模型的自动调整超参数。PyCaret 在预定义的搜索空间上使用随机网格搜索。此函数返回具有k倍交叉验证分数和训练有素的模型对象的表格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_adaboost = tune_model('ada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡特别提醒：tune_model位于无监督模块，如函数pycaret.nlp，pycaret.clustering和pycaret.anomal可与监督模块结合使用。例如，PyCaret的NLP模块可用于通过监督ML模型（例如“准确度”或“ R2”）评估目标/成本函数来调整主题参数（topics parameter）的数量\n",
    "\n",
    "# 6.集成模型\n",
    "ensemble_model功能用于ensembling训练的模型。它仅采用一个参数，即经过训练的模型对象。此函数返回具有k倍交叉验证得分和训练模型对象的表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a decision tree model\n",
    "dt = create_model('dt')\n",
    "# ensembling a trained dt model\n",
    "dt_bagged = ensemble_model(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡特别提醒：\n",
    "默认情况下，“Bagging”方法用于ensembling，可使用ensemble_model函数中的method参数将其更改为“Boosting” 。\n",
    "PyCaret还提供blend_models和stack_models功能来集成多个训练过的模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.显示模型\n",
    "可以使用plot_model函数对经过训练的机器学习模型进行性能评估和诊断。它使用训练有素的模型对象和作图的类型作为plot_model函数中的字符串输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "adaboost = create_model('ada')\n",
    "# AUC plot\n",
    "plot_model(adaboost, plot = 'auc')\n",
    "# Decision Boundary\n",
    "plot_model(adaboost, plot = 'boundary')\n",
    "# Precision Recall Curve\n",
    "plot_model(adaboost, plot = 'pr')\n",
    "# Validation Curve\n",
    "plot_model(adaboost, plot = 'vc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "了解有关PyCaret中不同可视化的更多信息：https://www.pycaret.org/plot-model\n",
    "或者，\n",
    "# 您可以使用评估模型（evaluate_model）函数通过botebook中的用户界面查看作图效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡特别提醒： plot_model函数pycaret.nlp模块可用于显示文本语料库和语义主题模型。\n",
    "# 8.解释模型\n",
    "在现实生活中通常是这样，当数据之间的关系是非线性时，我们总是看到基于树的模型（tree-based ）比简单的高斯模型（simple gaussian models）做得更好。但是，这是以失去可解释性为代价的，因为基于树的模型没有像线性模型那样提供简单的系数。PyCaret 使用interpret_model函数实现SHAP（SHapley Additive exPlanations）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "xgboost = create_model('xgboost')\n",
    "# summary plot\n",
    "interpret_model(xgboost)\n",
    "# correlation plot\n",
    "interpret_model(xgboost, plot = 'correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用“plot = 'reason'”评估测试数据集中特定数据点（也称为原因自变量'reason argument'）的解释。在下面的示例中，我们正在检查测试数据集中的第一个实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_model(xgboost, plot = 'reason', observation = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.预测模型\n",
    "\n",
    "到目前为止，我们看到的结果仅基于训练数据集的k倍交叉验证（默认为70％）。为了查看模型在test / hold-out上的预测和性能，使用了predict_model函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "rf = create_model('rf')\n",
    "# predict test / hold-out dataset\n",
    "rf_holdout_pred = predict_model(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict_model函数还用于预测未知的数据集\n",
    "。现在，我们将使用与训练时相同的数据集作为新的未知数据集的代理（proxy ）。实际上，每次使用新的未知数据集时，predict_model函数将被迭代使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_model(rf, data = diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡特别提醒：\n",
    "\n",
    "predict_model函数还可以预测使用stack_models和create_stacknet函数创建的模型的顺序链（sequential chain）。\n",
    "\n",
    "predict_model函数还可以使用deploy_model函数直接从AWS S3上托管的模型进行预测。\n",
    "\n",
    "\n",
    "# 10.部署模型\n",
    "利用训练后的模型在未知数据集上生成预测的一种方法是：在训练过模型的同一notebooks / IDE中使用predict_model函数。但是，对未知数据集进行预测是一个迭代过程。根据用例，进行预测的频率可以是从实时预测到批量预测。PyCaret的deploy_model函数允许notebook环境在云端部署整个管道，包括经过训练的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#deploy_model(model = rf, model_name = 'rf_aws', platform = 'aws',authentication =  {'bucket'  : 'pycaret-test'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.保存模型/保存实验\n",
    "训练完成后，包含所有预处理转换和训练后的模型对象的整个管道都可以保存为二进制pickle文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "adaboost = create_model('ada')\n",
    "# saving model\n",
    "save_model(adaboost, model_name = 'ada_for_deployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您还可以将包含所有中间输出的整个实验保存为一个二进制文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_experiment(experiment_name = 'my_first_experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡特别提醒：您可以使用PyCaret所有模块中可用的load_model和load_experiment函数加载保存的模型和保存的实验。\n",
    "\n",
    "延伸阅读\n",
    "【1】回归：https://pycaret.org/reg101/\n",
    "【2】聚类：https://pycaret.org/clu101/\n",
    "【3】异常检测：https://www.pycaret.org/anom101\n",
    "【4】自然语言处理：https://pycaret.org/nlp101/\n",
    "【5】关联规则挖掘：https://pycaret.org/arul101/\n",
    "【6】预处理功能：https://www.pycaret.org/preprocessing\n",
    "【7】模型列表：https://www.pycaret.org/create-model\n",
    "【8】可视化信息：https://www.pycaret.org/plot-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
