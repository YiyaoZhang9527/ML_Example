{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tkinter\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $ Q(s_1,a_2)_{reality} = R + \\gamma * Q_{max} 现实 $\n",
    "# $ Q(s_1,a_2)_{estimated} = Q(s_1,a_2) 估计$\n",
    "# $ GAP_i = Q(s_1,a_2)_{reality} - Q(s_1,a_2)_{estimated} 差距 $\n",
    "# $ Q(s_1,a_2)_{new} = Q(s_1,a_2)_{old} + \\alpha * GAP_i $\n",
    "### $ R是到达Q\\gamma时所获得的奖励 ，\\gamma 是奖励的衰减值 $\n",
    "### $ Q_{max} 是信息表中奖励更大的选择  \\alpha 是学习效率 $\n",
    "### $ {s_2 update == \\True \\and \\to s_2 } $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     a1   a2   a3   a4   a5   a6   a7   a8   a9  a10\ns1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\ns2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a1</th>\n      <th>a2</th>\n      <th>a3</th>\n      <th>a4</th>\n      <th>a5</th>\n      <th>a6</th>\n      <th>a7</th>\n      <th>a8</th>\n      <th>a9</th>\n      <th>a10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>s1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>s2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "infotable = pd.DataFrame(np.zeros((10,2)).T)\n",
    "infotable.columns=[\"{}{}\".format('a',i) for i in range(1,11)]\n",
    "infotable.index = ['s1','s2']\n",
    "infotable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0000\n190 Episode finished after 9.000000 time steps / mean 18.850000\n191 Episode finished after 22.000000 time steps / mean 18.840000\n192 Episode finished after 26.000000 time steps / mean 18.970000\n193 Episode finished after 8.000000 time steps / mean 19.150000\n194 Episode finished after 11.000000 time steps / mean 19.150000\n195 Episode finished after 9.000000 time steps / mean 18.820000\n196 Episode finished after 9.000000 time steps / mean 18.820000\n197 Episode finished after 8.000000 time steps / mean 18.820000\n198 Episode finished after 9.000000 time steps / mean 18.810000\n199 Episode finished after 9.000000 time steps / mean 18.810000\n200 Episode finished after 9.000000 time steps / mean 18.810000\n201 Episode finished after 8.000000 time steps / mean 18.810000\n202 Episode finished after 9.000000 time steps / mean 18.780000\n203 Episode finished after 13.000000 time steps / mean 18.780000\n204 Episode finished after 37.000000 time steps / mean 18.780000\n205 Episode finished after 45.000000 time steps / mean 18.930000\n206 Episode finished after 8.000000 time steps / mean 19.290000\n207 Episode finished after 8.000000 time steps / mean 19.280000\n208 Episode finished after 9.000000 time steps / mean 19.270000\n209 Episode finished after 15.000000 time steps / mean 19.270000\n210 Episode finished after 13.000000 time steps / mean 19.330000\n211 Episode finished after 17.000000 time steps / mean 19.370000\n212 Episode finished after 11.000000 time steps / mean 19.430000\n213 Episode finished after 56.000000 time steps / mean 19.460000\n214 Episode finished after 11.000000 time steps / mean 19.800000\n215 Episode finished after 9.000000 time steps / mean 19.820000\n216 Episode finished after 9.000000 time steps / mean 19.830000\n217 Episode finished after 45.000000 time steps / mean 19.550000\n218 Episode finished after 12.000000 time steps / mean 19.910000\n219 Episode finished after 8.000000 time steps / mean 19.940000\n220 Episode finished after 9.000000 time steps / mean 19.550000\n221 Episode finished after 9.000000 time steps / mean 19.330000\n222 Episode finished after 29.000000 time steps / mean 19.340000\n223 Episode finished after 10.000000 time steps / mean 19.540000\n224 Episode finished after 10.000000 time steps / mean 19.180000\n225 Episode finished after 34.000000 time steps / mean 18.330000\n226 Episode finished after 10.000000 time steps / mean 17.860000\n227 Episode finished after 11.000000 time steps / mean 17.870000\n228 Episode finished after 77.000000 time steps / mean 17.490000\n229 Episode finished after 10.000000 time steps / mean 18.140000\n230 Episode finished after 11.000000 time steps / mean 18.150000\n231 Episode finished after 26.000000 time steps / mean 18.170000\n232 Episode finished after 9.000000 time steps / mean 17.990000\n233 Episode finished after 8.000000 time steps / mean 17.990000\n234 Episode finished after 8.000000 time steps / mean 17.980000\n235 Episode finished after 13.000000 time steps / mean 17.970000\n236 Episode finished after 9.000000 time steps / mean 18.010000\n237 Episode finished after 14.000000 time steps / mean 18.010000\n238 Episode finished after 9.000000 time steps / mean 18.060000\n239 Episode finished after 10.000000 time steps / mean 17.760000\n240 Episode finished after 9.000000 time steps / mean 17.730000\n241 Episode finished after 24.000000 time steps / mean 17.720000\n242 Episode finished after 39.000000 time steps / mean 17.870000\n243 Episode finished after 8.000000 time steps / mean 18.130000\n244 Episode finished after 42.000000 time steps / mean 18.130000\n245 Episode finished after 9.000000 time steps / mean 18.180000\n246 Episode finished after 8.000000 time steps / mean 18.160000\n247 Episode finished after 9.000000 time steps / mean 17.970000\n248 Episode finished after 11.000000 time steps / mean 17.430000\n249 Episode finished after 9.000000 time steps / mean 17.460000\n250 Episode finished after 8.000000 time steps / mean 17.460000\n251 Episode finished after 8.000000 time steps / mean 17.450000\n252 Episode finished after 9.000000 time steps / mean 17.440000\n253 Episode finished after 9.000000 time steps / mean 17.110000\n254 Episode finished after 9.000000 time steps / mean 17.110000\n255 Episode finished after 8.000000 time steps / mean 17.120000\n256 Episode finished after 9.000000 time steps / mean 17.090000\n257 Episode finished after 9.000000 time steps / mean 17.090000\n258 Episode finished after 15.000000 time steps / mean 17.090000\n259 Episode finished after 47.000000 time steps / mean 16.980000\n260 Episode finished after 8.000000 time steps / mean 17.350000\n261 Episode finished after 14.000000 time steps / mean 17.350000\n262 Episode finished after 9.000000 time steps / mean 17.360000\n263 Episode finished after 9.000000 time steps / mean 16.940000\n264 Episode finished after 31.000000 time steps / mean 16.940000\n265 Episode finished after 9.000000 time steps / mean 16.450000\n266 Episode finished after 9.000000 time steps / mean 16.450000\n267 Episode finished after 8.000000 time steps / mean 16.100000\n268 Episode finished after 11.000000 time steps / mean 16.090000\n269 Episode finished after 8.000000 time steps / mean 15.890000\n270 Episode finished after 8.000000 time steps / mean 15.880000\n271 Episode finished after 8.000000 time steps / mean 15.870000\n272 Episode finished after 27.000000 time steps / mean 15.610000\n273 Episode finished after 9.000000 time steps / mean 15.030000\n274 Episode finished after 9.000000 time steps / mean 14.990000\n275 Episode finished after 13.000000 time steps / mean 14.660000\n276 Episode finished after 27.000000 time steps / mean 14.700000\n277 Episode finished after 9.000000 time steps / mean 14.890000\n278 Episode finished after 10.000000 time steps / mean 14.890000\n279 Episode finished after 31.000000 time steps / mean 14.710000\n280 Episode finished after 13.000000 time steps / mean 14.690000\n281 Episode finished after 8.000000 time steps / mean 14.730000\n282 Episode finished after 9.000000 time steps / mean 14.700000\n283 Episode finished after 35.000000 time steps / mean 14.560000\n284 Episode finished after 20.000000 time steps / mean 14.820000\n285 Episode finished after 9.000000 time steps / mean 14.930000\n286 Episode finished after 8.000000 time steps / mean 14.940000\n287 Episode finished after 9.000000 time steps / mean 14.940000\n288 Episode finished after 9.000000 time steps / mean 14.940000\n289 Episode finished after 8.000000 time steps / mean 14.940000\n290 Episode finished after 10.000000 time steps / mean 14.920000\n291 Episode finished after 8.000000 time steps / mean 14.930000\n292 Episode finished after 44.000000 time steps / mean 14.790000\n293 Episode finished after 55.000000 time steps / mean 14.970000\n294 Episode finished after 43.000000 time steps / mean 15.440000\n295 Episode finished after 8.000000 time steps / mean 15.760000\n296 Episode finished after 14.000000 time steps / mean 15.750000\n297 Episode finished after 8.000000 time steps / mean 15.800000\n298 Episode finished after 10.000000 time steps / mean 15.800000\n299 Episode finished after 9.000000 time steps / mean 15.810000\n300 Episode finished after 9.000000 time steps / mean 15.810000\n301 Episode finished after 32.000000 time steps / mean 15.810000\n302 Episode finished after 8.000000 time steps / mean 16.050000\n303 Episode finished after 9.000000 time steps / mean 16.040000\n304 Episode finished after 8.000000 time steps / mean 16.000000\n305 Episode finished after 10.000000 time steps / mean 15.710000\n306 Episode finished after 30.000000 time steps / mean 15.360000\n307 Episode finished after 43.000000 time steps / mean 15.580000\n308 Episode finished after 35.000000 time steps / mean 15.930000\n309 Episode finished after 34.000000 time steps / mean 16.190000\n310 Episode finished after 9.000000 time steps / mean 16.380000\n311 Episode finished after 29.000000 time steps / mean 16.340000\n312 Episode finished after 40.000000 time steps / mean 16.460000\n313 Episode finished after 8.000000 time steps / mean 16.750000\n314 Episode finished after 9.000000 time steps / mean 16.270000\n315 Episode finished after 8.000000 time steps / mean 16.250000\n316 Episode finished after 23.000000 time steps / mean 16.240000\n317 Episode finished after 9.000000 time steps / mean 16.380000\n318 Episode finished after 25.000000 time steps / mean 16.020000\n319 Episode finished after 8.000000 time steps / mean 16.150000\n320 Episode finished after 9.000000 time steps / mean 16.150000\n321 Episode finished after 9.000000 time steps / mean 16.150000\n322 Episode finished after 10.000000 time steps / mean 16.150000\n323 Episode finished after 11.000000 time steps / mean 15.960000\n324 Episode finished after 36.000000 time steps / mean 15.970000\n325 Episode finished after 9.000000 time steps / mean 16.230000\n326 Episode finished after 41.000000 time steps / mean 15.980000\n327 Episode finished after 10.000000 time steps / mean 16.290000\n328 Episode finished after 13.000000 time steps / mean 16.280000\n329 Episode finished after 9.000000 time steps / mean 15.640000\n330 Episode finished after 10.000000 time steps / mean 15.630000\n331 Episode finished after 9.000000 time steps / mean 15.620000\n332 Episode finished after 9.000000 time steps / mean 15.450000\n333 Episode finished after 9.000000 time steps / mean 15.450000\n334 Episode finished after 8.000000 time steps / mean 15.460000\n335 Episode finished after 9.000000 time steps / mean 15.460000\n336 Episode finished after 9.000000 time steps / mean 15.420000\n337 Episode finished after 8.000000 time steps / mean 15.420000\n338 Episode finished after 10.000000 time steps / mean 15.360000\n339 Episode finished after 9.000000 time steps / mean 15.370000\n340 Episode finished after 24.000000 time steps / mean 15.360000\n341 Episode finished after 13.000000 time steps / mean 15.510000\n342 Episode finished after 54.000000 time steps / mean 15.400000\n343 Episode finished after 9.000000 time steps / mean 15.550000\n344 Episode finished after 60.000000 time steps / mean 15.560000\n345 Episode finished after 9.000000 time steps / mean 15.740000\n346 Episode finished after 8.000000 time steps / mean 15.740000\n347 Episode finished after 11.000000 time steps / mean 15.740000\n348 Episode finished after 9.000000 time steps / mean 15.760000\n349 Episode finished after 11.000000 time steps / mean 15.740000\n350 Episode finished after 29.000000 time steps / mean 15.760000\n351 Episode finished after 8.000000 time steps / mean 15.970000\n352 Episode finished after 9.000000 time steps / mean 15.970000\n353 Episode finished after 48.000000 time steps / mean 15.970000\n354 Episode finished after 13.000000 time steps / mean 16.360000\n355 Episode finished after 34.000000 time steps / mean 16.400000\n356 Episode finished after 9.000000 time steps / mean 16.660000\n357 Episode finished after 9.000000 time steps / mean 16.660000\n358 Episode finished after 9.000000 time steps / mean 16.660000\n359 Episode finished after 9.000000 time steps / mean 16.600000\n360 Episode finished after 9.000000 time steps / mean 16.220000\n361 Episode finished after 28.000000 time steps / mean 16.230000\n362 Episode finished after 8.000000 time steps / mean 16.370000\n363 Episode finished after 9.000000 time steps / mean 16.360000\n364 Episode finished after 38.000000 time steps / mean 16.360000\n365 Episode finished after 9.000000 time steps / mean 16.430000\n366 Episode finished after 19.000000 time steps / mean 16.430000\n367 Episode finished after 9.000000 time steps / mean 16.530000\n368 Episode finished after 9.000000 time steps / mean 16.540000\n369 Episode finished after 9.000000 time steps / mean 16.520000\n370 Episode finished after 9.000000 time steps / mean 16.530000\n371 Episode finished after 19.000000 time steps / mean 16.540000\n372 Episode finished after 63.000000 time steps / mean 16.650000\n373 Episode finished after 35.000000 time steps / mean 17.010000\n374 Episode finished after 23.000000 time steps / mean 17.270000\n375 Episode finished after 8.000000 time steps / mean 17.410000\n376 Episode finished after 72.000000 time steps / mean 17.360000\n377 Episode finished after 8.000000 time steps / mean 17.810000\n378 Episode finished after 28.000000 time steps / mean 17.800000\n379 Episode finished after 57.000000 time steps / mean 17.980000\n380 Episode finished after 9.000000 time steps / mean 18.240000\n381 Episode finished after 9.000000 time steps / mean 18.200000\n382 Episode finished after 11.000000 time steps / mean 18.210000\n383 Episode finished after 18.000000 time steps / mean 18.230000\n384 Episode finished after 11.000000 time steps / mean 18.060000\n385 Episode finished after 49.000000 time steps / mean 17.970000\n386 Episode finished after 57.000000 time steps / mean 18.370000\n387 Episode finished after 10.000000 time steps / mean 18.860000\n388 Episode finished after 8.000000 time steps / mean 18.870000\n389 Episode finished after 10.000000 time steps / mean 18.860000\n390 Episode finished after 15.000000 time steps / mean 18.880000\n391 Episode finished after 11.000000 time steps / mean 18.930000\n392 Episode finished after 8.000000 time steps / mean 18.960000\n393 Episode finished after 9.000000 time steps / mean 18.600000\n394 Episode finished after 9.000000 time steps / mean 18.140000\n395 Episode finished after 30.000000 time steps / mean 17.800000\n396 Episode finished after 40.000000 time steps / mean 18.020000\n397 Episode finished after 35.000000 time steps / mean 18.280000\n398 Episode finished after 40.000000 time steps / mean 18.550000\n399 Episode finished after 8.000000 time steps / mean 18.850000\n400 Episode finished after 28.000000 time steps / mean 18.840000\n401 Episode finished after 11.000000 time steps / mean 19.030000\n402 Episode finished after 9.000000 time steps / mean 18.820000\n403 Episode finished after 9.000000 time steps / mean 18.830000\n404 Episode finished after 45.000000 time steps / mean 18.830000\n405 Episode finished after 10.000000 time steps / mean 19.200000\n406 Episode finished after 9.000000 time steps / mean 19.200000\n407 Episode finished after 11.000000 time steps / mean 18.990000\n408 Episode finished after 9.000000 time steps / mean 18.670000\n409 Episode finished after 9.000000 time steps / mean 18.410000\n410 Episode finished after 9.000000 time steps / mean 18.160000\n411 Episode finished after 9.000000 time steps / mean 18.160000\n412 Episode finished after 9.000000 time steps / mean 17.960000\n413 Episode finished after 12.000000 time steps / mean 17.650000\n414 Episode finished after 9.000000 time steps / mean 17.690000\n415 Episode finished after 31.000000 time steps / mean 17.690000\n416 Episode finished after 26.000000 time steps / mean 17.920000\n417 Episode finished after 36.000000 time steps / mean 17.950000\n418 Episode finished after 37.000000 time steps / mean 18.220000\n419 Episode finished after 10.000000 time steps / mean 18.340000\n420 Episode finished after 11.000000 time steps / mean 18.360000\n421 Episode finished after 27.000000 time steps / mean 18.380000\n422 Episode finished after 9.000000 time steps / mean 18.560000\n423 Episode finished after 15.000000 time steps / mean 18.550000\n424 Episode finished after 32.000000 time steps / mean 18.590000\n425 Episode finished after 9.000000 time steps / mean 18.550000\n426 Episode finished after 8.000000 time steps / mean 18.550000\n427 Episode finished after 9.000000 time steps / mean 18.220000\n428 Episode finished after 30.000000 time steps / mean 18.210000\n429 Episode finished after 9.000000 time steps / mean 18.380000\n430 Episode finished after 9.000000 time steps / mean 18.380000\n431 Episode finished after 11.000000 time steps / mean 18.370000\n432 Episode finished after 8.000000 time steps / mean 18.390000\n433 Episode finished after 8.000000 time steps / mean 18.380000\n434 Episode finished after 28.000000 time steps / mean 18.370000\n435 Episode finished after 25.000000 time steps / mean 18.570000\n436 Episode finished after 26.000000 time steps / mean 18.730000\n437 Episode finished after 9.000000 time steps / mean 18.900000\n438 Episode finished after 9.000000 time steps / mean 18.910000\n439 Episode finished after 9.000000 time steps / mean 18.900000\n440 Episode finished after 20.000000 time steps / mean 18.900000\n441 Episode finished after 9.000000 time steps / mean 18.860000\n442 Episode finished after 9.000000 time steps / mean 18.820000\n443 Episode finished after 9.000000 time steps / mean 18.370000\n444 Episode finished after 11.000000 time steps / mean 18.370000\n445 Episode finished after 11.000000 time steps / mean 17.880000\n446 Episode finished after 29.000000 time steps / mean 17.900000\n447 Episode finished after 9.000000 time steps / mean 18.110000\n448 Episode finished after 11.000000 time steps / mean 18.090000\n449 Episode finished after 9.000000 time steps / mean 18.110000\n450 Episode finished after 9.000000 time steps / mean 18.090000\n451 Episode finished after 9.000000 time steps / mean 17.890000\n452 Episode finished after 76.000000 time steps / mean 17.900000\n453 Episode finished after 9.000000 time steps / mean 18.570000\n454 Episode finished after 9.000000 time steps / mean 18.180000\n455 Episode finished after 9.000000 time steps / mean 18.140000\n456 Episode finished after 9.000000 time steps / mean 17.890000\n457 Episode finished after 9.000000 time steps / mean 17.890000\n458 Episode finished after 9.000000 time steps / mean 17.890000\n459 Episode finished after 9.000000 time steps / mean 17.890000\n460 Episode finished after 9.000000 time steps / mean 17.890000\n461 Episode finished after 38.000000 time steps / mean 17.890000\n462 Episode finished after 57.000000 time steps / mean 17.990000\n463 Episode finished after 30.000000 time steps / mean 18.480000\n464 Episode finished after 15.000000 time steps / mean 18.690000\n465 Episode finished after 9.000000 time steps / mean 18.460000\n466 Episode finished after 9.000000 time steps / mean 18.460000\n467 Episode finished after 19.000000 time steps / mean 18.360000\n468 Episode finished after 9.000000 time steps / mean 18.460000\n469 Episode finished after 52.000000 time steps / mean 18.460000\n470 Episode finished after 9.000000 time steps / mean 18.890000\n471 Episode finished after 9.000000 time steps / mean 18.890000\n472 Episode finished after 9.000000 time steps / mean 18.790000\n473 Episode finished after 8.000000 time steps / mean 18.250000\n474 Episode finished after 14.000000 time steps / mean 17.980000\n475 Episode finished after 9.000000 time steps / mean 17.890000\n476 Episode finished after 11.000000 time steps / mean 17.900000\n477 Episode finished after 10.000000 time steps / mean 17.290000\n478 Episode finished after 10.000000 time steps / mean 17.310000\n479 Episode finished after 10.000000 time steps / mean 17.130000\n480 Episode finished after 11.000000 time steps / mean 16.660000\n481 Episode finished after 9.000000 time steps / mean 16.680000\n482 Episode finished after 67.000000 time steps / mean 16.680000\n483 Episode finished after 8.000000 time steps / mean 17.240000\n484 Episode finished after 9.000000 time steps / mean 17.140000\n485 Episode finished after 29.000000 time steps / mean 17.120000\n486 Episode finished after 41.000000 time steps / mean 16.920000\n487 Episode finished after 9.000000 time steps / mean 16.760000\n488 Episode finished after 10.000000 time steps / mean 16.750000\n489 Episode finished after 8.000000 time steps / mean 16.770000\n490 Episode finished after 52.000000 time steps / mean 16.750000\n491 Episode finished after 9.000000 time steps / mean 17.120000\n492 Episode finished after 30.000000 time steps / mean 17.100000\n493 Episode finished after 8.000000 time steps / mean 17.320000\n494 Episode finished after 13.000000 time steps / mean 17.310000\n495 Episode finished after 59.000000 time steps / mean 17.350000\n496 Episode finished after 8.000000 time steps / mean 17.640000\n497 Episode finished after 8.000000 time steps / mean 17.320000\n498 Episode finished after 9.000000 time steps / mean 17.050000\n499 Episode finished after 9.000000 time steps / mean 16.740000\nFailed!\n"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "max_number_of_steps = 200   # 每一场游戏的最高得分\n",
    "#---------获胜的条件是最近100场平均得分高于195-------------\n",
    "goal_average_steps = 195\n",
    "num_consecutive_iterations = 100\n",
    "#----------------------------------------------------------\n",
    "num_episodes = 500#0 # 共进行5000场游戏\n",
    "last_time_steps = np.zeros(num_consecutive_iterations)  # 只存储最近100场的得分（可以理解为是一个容量为100的栈）\n",
    "\n",
    "# q_table是一个256*2的二维数组\n",
    "# 离散化后的状态共有4^4=256中可能的取值，每种状态会对应一个行动\n",
    "# q_table[s][a]就是当状态为s时作出行动a的有利程度评价值\n",
    "# 我们的AI模型要训练学习的就是这个映射关系表\n",
    "q_table = np.random.uniform(low=-1, high=1, size=(4 ** 4, env.action_space.n))\n",
    "\n",
    "# 分箱处理函数，把[clip_min,clip_max]区间平均分为num段，位于i段区间的特征值x会被离散化为i\n",
    "def bins(clip_min, clip_max, num):\n",
    "    return np.linspace(clip_min, clip_max, num + 1)[1:-1]\n",
    "\n",
    "# 离散化处理，将由4个连续特征值组成的状态矢量转换为一个0~~255的整数离散值\n",
    "def digitize_state(observation):\n",
    "    # 将矢量打散回4个连续特征值\n",
    "    cart_pos, cart_v, pole_angle, pole_v = observation\n",
    "    # 分别对各个连续特征值进行离散化（分箱处理）\n",
    "    digitized = [np.digitize(cart_pos, bins=bins(-2.4, 2.4, 4)),\n",
    "                 np.digitize(cart_v, bins=bins(-3.0, 3.0, 4)),\n",
    "                 np.digitize(pole_angle, bins=bins(-0.5, 0.5, 4)),\n",
    "                 np.digitize(pole_v, bins=bins(-2.0, 2.0, 4))]\n",
    "    # 将4个离散值再组合为一个离散值，作为最终结果\n",
    "    return sum([x * (4 ** i) for i, x in enumerate(digitized)])\n",
    "\n",
    "# 根据本次的行动及其反馈（下一个时间步的状态），返回下一次的最佳行动\n",
    "def get_action(state, action, observation, reward):\n",
    "    next_state = digitize_state(observation)    # 获取下一个时间步的状态，并将其离散化\n",
    "    #print(next_state)\n",
    "    next_action = np.argmax(q_table[next_state])    # 查表得到最佳行动\n",
    "    #-------------------------------------训练学习，更新q_table----------------------------------\n",
    "    alpha = 0.2     # 学习系数α\n",
    "    gamma = 0.99    # 报酬衰减系数γ\n",
    "    q_table[state, action] = (1 - alpha) * q_table[state, action] + alpha * (reward + gamma * q_table[next_state, next_action])\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    return next_action, next_state\n",
    "\n",
    "# 重复进行一场场的游戏\n",
    "for episode in range(num_episodes):\n",
    "    observation = env.reset()   # 初始化本场游戏的环境\n",
    "    state = digitize_state(observation)     # 获取初始状态值\n",
    "    action = np.argmax(q_table[state])      # 根据状态值作出行动决策\n",
    "    episode_reward = 0\n",
    "    # 一场游戏分为一个个时间步\n",
    "    for t in range(max_number_of_steps):\n",
    "        env.render()    # 更新并渲染游戏画面\n",
    "        observation, reward, done, info = env.step(action)  # 获取本次行动的反馈结果\n",
    "        action, state = get_action(state, action, observation, reward)  # 作出下一次行动的决策\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            print('%d Episode finished after %f time steps / mean %f' % (episode, t + 1, last_time_steps.mean()))\n",
    "            last_time_steps = np.hstack((last_time_steps[1:], [episode_reward]))  # 更新最近100场游戏的得分stack\n",
    "            break\n",
    "            # 如果最近100场平均得分高于195\n",
    "        if (last_time_steps.mean() >= goal_average_steps):\n",
    "            print('Episode %d train agent successfuly!' % episode)\n",
    "            break\n",
    "        log = open(\"/Users/manmanzhang/Library/Mobile Documents/com~apple~CloudDocs/MyProject/InferenceSystem/src/I5_algorithm/强化学习log日志/qlearning.log\",'a+')\n",
    "        log.write(str('Episode %d train agent successfuly!' % episode))\n",
    "    log.close()\n",
    "\n",
    "\n",
    "print('Failed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-66c53067",
   "display_name": "PyCharm (InferenceSystem)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}