{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnsenti import Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文文本情感词正负情感词统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/sl/q8x6_03132dfk7rktf00yh880000gn/T/jieba.cache\n",
      "Loading model cost 0.730 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': 3, 'sentences': 1, 'pos': 0, 'neg': 0}\n"
     ]
    }
   ],
   "source": [
    "senti = Sentiment()\n",
    "test_text= '这是一个岑氏'\n",
    "result = senti.sentiment_count(test_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文文本情绪统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': 173, 'sentences': 21, '好': 15, '乐': 0, '哀': 0, '怒': 0, '惧': 0, '恶': 0, '惊': 0}\n"
     ]
    }
   ],
   "source": [
    "from cnsenti import Emotion\n",
    "\n",
    "emotion = Emotion()\n",
    "test_text = '岗位职责:1.研究基于RL的网络结构搜索算法，要求能应对server和嵌入式的不同需求。2.研究基于RL的模型压缩算法，大规模数据聚类算法，实现自动化。3.研究基于RL的机器人室内导航算法，可以快速适应新的室内环境，自主探索。4.密切关注领域内的最新进展。职位要求：1.具备扎实的强化学习理论的基础。2.有用强化学习解决问题的经验，最好是有分布式方面的编程经验。3.具备python和cpp的编程经验，熟练至少一种深度学习框架。4.了解强化学习的一些应用案例，在game上的发展现状，还有在其它领域对实际产品的一些帮助。5.了解一些经典的强化学习算法，能区分异同和优缺点。6.具备不断进取，紧跟前沿的能力和热情。'\n",
    "result = emotion.emotion_count(test_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/117673231?utm_source=ZHShareTargetIDMore&utm_medium=social&utm_oi=737646268834152448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "strings = {'cad', 'PE ', 'Window', 'FM', 'hello', 'world','flowers'}\n",
    "n=0\n",
    "for word in strings:\n",
    "    if word.islower:\n",
    "        n += 1\n",
    "print(n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'CadTef'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.Cad.Tef'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([i.islower() == False and \"{}{}\".format('.',i) or i for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.Cad.Tef'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def splitEnglish(letter):\n",
    "    return ''.join([i.islower() == False and \"{}{}\".format('.',i) or i for i in letter])\n",
    "\n",
    "splitEnglish(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'算法神经网络.CNN.RNN.DNN.BP.Matlab.python.Python.C.聚类.回归.研发.Deep.Learning.Tensorflow'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = '算法神经网络.CNN.RNN.DNN.BP.Matlab.python.Python.C.聚类.回归.研发DeepLearningTensorflow'\n",
    "def splitEnglish(letter):\n",
    "    m =len(letter)\n",
    "    indexB = [letter[i].istitle() for i in range(m)]\n",
    "    splitpoints = []\n",
    "    strlist = []\n",
    "    n = 0\n",
    "    for i in range(m):  \n",
    "        if indexB[i]==1:\n",
    "            n += 1\n",
    "            if n == 1:\n",
    "                strlist.append('.')\n",
    "                strlist.append(letter[i])\n",
    "            else:\n",
    "                strlist.append(letter[i])\n",
    "        else:\n",
    "            n = 0\n",
    "            strlist.append(letter[i])\n",
    "    return ''.join(strlist).replace('..','.')\n",
    "\n",
    "splitEnglish(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('算', False),\n",
       " ('法', False),\n",
       " ('神', False),\n",
       " ('经', False),\n",
       " ('网', False),\n",
       " ('络', False),\n",
       " ('.', False),\n",
       " ('C', True),\n",
       " ('N', True),\n",
       " ('N', True),\n",
       " ('.', False),\n",
       " ('R', True),\n",
       " ('N', True),\n",
       " ('N', True),\n",
       " ('.', False),\n",
       " ('D', True),\n",
       " ('N', True),\n",
       " ('N', True),\n",
       " ('.', False),\n",
       " ('B', True),\n",
       " ('P', True),\n",
       " ('.', False),\n",
       " ('M', True),\n",
       " ('a', False),\n",
       " ('t', False),\n",
       " ('l', False),\n",
       " ('a', False),\n",
       " ('b', False),\n",
       " ('.', False),\n",
       " ('p', False),\n",
       " ('y', False),\n",
       " ('t', False),\n",
       " ('h', False),\n",
       " ('o', False),\n",
       " ('n', False),\n",
       " ('.', False),\n",
       " ('P', True),\n",
       " ('y', False),\n",
       " ('t', False),\n",
       " ('h', False),\n",
       " ('o', False),\n",
       " ('n', False),\n",
       " ('.', False),\n",
       " ('C', True),\n",
       " ('.', False),\n",
       " ('聚', False),\n",
       " ('类', False),\n",
       " ('.', False),\n",
       " ('回', False),\n",
       " ('归', False),\n",
       " ('.', False),\n",
       " ('研', False),\n",
       " ('发', False),\n",
       " ('D', True),\n",
       " ('e', False),\n",
       " ('e', False),\n",
       " ('p', False),\n",
       " ('L', True),\n",
       " ('e', False),\n",
       " ('a', False),\n",
       " ('r', False),\n",
       " ('n', False),\n",
       " ('i', False),\n",
       " ('n', False),\n",
       " ('g', False),\n",
       " ('T', True),\n",
       " ('e', False),\n",
       " ('n', False),\n",
       " ('s', False),\n",
       " ('o', False),\n",
       " ('r', False),\n",
       " ('f', False),\n",
       " ('l', False),\n",
       " ('o', False),\n",
       " ('w', False)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,i.istitle()) for i in a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_list(text):\n",
    "    # 情感分析向量list结构\n",
    "    emotion = Emotion()\n",
    "    emotiondict = emotion.emotion_count(text)\n",
    "    emotionkeys = ('words', 'sentences', '好', '乐', '哀', '怒', '惧', '恶', '惊')\n",
    "    return [emotiondict[i] for i in emotionkeys]\n",
    "\n",
    "def emotion_dict(textList):\n",
    "    # 多文本情感分析，输入list(str,str)，输出字典结构，可直接转dataframe\n",
    "    emotionData = np.array([emotion_list(words) for words in textList])\n",
    "    words,sentences,good,joy,sorrow,anger,fear,evil,fright = [],[],[],[],[],[],[],[],[]\n",
    "    for values in emotionData:\n",
    "        words.append(values[0])\n",
    "        sentences.append(values[1])\n",
    "        good.append(values[2])\n",
    "        joy.append(values[3])\n",
    "        sorrow.append(values[4])\n",
    "        anger.append(values[5])\n",
    "        fear.append(values[6])\n",
    "        evil.append(values[7])\n",
    "        fright.append(values[8])\n",
    "    return {\"words\":words,\"sentences\":sentences\n",
    "     ,\"good\":good,\"joy\":joy\n",
    "     ,\"sorrow\":sorrow,\"anger\":anger\n",
    "     ,\"fear\":fear,\"evil\":evil\n",
    "     ,\"fright\":fright}"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "PyCharm (InferenceSystem)",
   "language": "python",
   "name": "pycharm-66c53067"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}