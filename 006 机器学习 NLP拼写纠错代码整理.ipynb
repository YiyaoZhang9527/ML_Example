{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok: THUOCL_lishimingren.txt\n",
      "ok: THUOCL_animal.txt\n",
      "ok: THUOCL_food.txt\n",
      "ok: THUOCL_chengyu.txt\n",
      "ok: THUOCL_car.txt\n",
      "ok: THUOCL_caijing.txt\n",
      "error: THUOCL_it.txt Wrong number of columns at line 89\n",
      "ok: THUOCL_law.txt\n",
      "ok: THUOCL_medical.txt\n",
      "ok: THUOCL_diming.txt\n",
      "ok: THUOCL_poem.txt\n",
      "The Function check_str Takes Time To Run : 3.3172181569999992 Seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'上海市'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jieba \n",
    "import pandas as pd\n",
    "import re\n",
    "from itertools import permutations\n",
    "import time\n",
    "from sys import exc_info,stdout\n",
    "import traceback\n",
    "from os import getcwd\n",
    "import os\n",
    "\n",
    "\n",
    "def shorterror(func):\n",
    "    def In(*vars):\n",
    "        try :\n",
    "            return func (*vars),\n",
    "        except Exception as e :\n",
    "            exc_type, exc_value, exc_traceback_obj = exc_info()\n",
    "            traceback.print_exception(exc_type, exc_value, exc_traceback_obj, limit=2, file=stdout)\n",
    "            print(\"exc_type: %s\" % exc_type)\n",
    "            print(\"exc_value: %s\" % exc_value)\n",
    "            print(\"exc_traceback_obj: %s\" % exc_traceback_obj)\n",
    "    return In\n",
    "\n",
    "def longerror(func):\n",
    "    def In(*vars):\n",
    "        try :\n",
    "            return func (*vars),\n",
    "        except Exception as e :\n",
    "            import cgitb\n",
    "            cgitb.enable ( format = 'text' )\n",
    "        return func (*vars),\n",
    "    return In\n",
    "\n",
    "def calltime(func):\n",
    "    def In(*varc):\n",
    "        start = time.process_time()\n",
    "        func(*varc)\n",
    "        print('The Function',func.__name__,'Takes Time To Run :',time.process_time() - start,'Seconds')\n",
    "        return func(*varc)\n",
    "    return In\n",
    "\n",
    "\n",
    "\n",
    "symbles=''':,\"{[}](>)</\\n。●  ，、的 啊 好 和\n",
    "并 与 及 对 错 你 我 我们 她 他 它：: ; ；《 》\n",
    "1 2 3 4 5 6 7 8 9 0  ‘ “ ” ’ + - * / ` ~ \n",
    "\\( \\ [ \\ { \\ } ] ) （ ）【 \\xa0 】理想 愿景\n",
    "工 不管 只要 一员 大家庭 当成 作 帅哥 美女 年轻\n",
    "佛系\n",
    "'''\n",
    "#删除停词\n",
    "def del_stop_word(strings,symbles=symbles):\n",
    "    srcrep = {i:'' for i in symbles }\n",
    "    rep = dict((re.escape(k), v) for k, v in srcrep.items())\n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    return pattern.sub(lambda m: rep[re.escape(m.group(0))], strings)\n",
    "    \n",
    "#读取文档\n",
    "def read_txt(path):\n",
    "    return open(path,'r').read()\n",
    " \n",
    "#只要中文\n",
    "def just_chinese(string, resymbol=\"\"):\n",
    "    return re.sub(u\"([^\\u4e00-\\u9fa5])\", resymbol, string)\n",
    "\n",
    "#分词\n",
    "def split_world(corpus):\n",
    "    return np.array(list(jieba.cut(just_chinese(read_txt(corpus)))))\n",
    "\n",
    "#整理成词典\n",
    "def word_dict_func(corpus,log=False):\n",
    "    word_list = split_world(corpus)\n",
    "    m = np.count_nonzero(word_list)\n",
    "    kind,count = np.unique(word_list,return_counts=True)\n",
    "    if log:\n",
    "        prob = -np.log(count/m)\n",
    "    else:\n",
    "        prob = count/m\n",
    "    return dict(zip(kind,prob))\n",
    "\n",
    "\n",
    "# 加载本地词典\n",
    "#只要数字\n",
    "def just_number(string, resymbol=\"\"):\n",
    "    sub_str = re.sub(u\"([^\\u0030-\\u0039])\", resymbol, string)\n",
    "    return sub_str\n",
    "\n",
    "#sigmod预留函数，转概率空前备用\n",
    "def sigmod(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "#过滤字词语频率生成字典\n",
    "def filter_dict(words,numbers):\n",
    "    word_dict ,expr_sum = dict(),0\n",
    "    for word,num in zip(words,numbers):\n",
    "        try:\n",
    "            number = float(just_number(num))\n",
    "            expr = {word:number}  \n",
    "        except Exception:\n",
    "            number = 0\n",
    "        finally:\n",
    "            expr_sum += number\n",
    "            word_dict.update(expr)\n",
    "    prob = {word:word_dict[word]/expr_sum for word in word_dict}\n",
    "    return prob\n",
    "\n",
    "#加载本地字典入口函数\n",
    "def location_dict(dir_path):\n",
    "    init_dict = np.zeros((2,2))\n",
    "    for path in os.listdir(dir_path):\n",
    "        try:\n",
    "            file_path = \"{}{}\".format(dir_path,path)\n",
    "            file_of_one = np.loadtxt(file_path,delimiter='\\t',dtype=str)\n",
    "            print(\"ok:\",path)\n",
    "        except Exception as error:\n",
    "            file_of_one = np.array([line.replace(\"\\n\",\"\").split(\"\\t\") for line in open(file_path,'r').readlines()])\n",
    "            print(\"error:\",path,error)\n",
    "        finally :\n",
    "            init_dict = np.r_[init_dict,file_of_one]\n",
    "    words,numbers = init_dict[2:,0],init_dict[2:,1]\n",
    "    return filter_dict(words,numbers)\n",
    "\n",
    "\n",
    "\n",
    "#生成单词补充模块\n",
    "#创建补充单词字典\n",
    "def create_char_map(str_range = 'lowercase',chinese_path = False):\n",
    "    iter_range = lambda char_range : map(lambda x : chr(x),char_range)\n",
    "    func_dict = {'lowercase':iter_range(range(97,122))\n",
    "                ,'uppercase':iter_range(range(65,90))\n",
    "                ,'numbers':iter_range(range(48,57))\n",
    "                ,'chinese':tuple(set(just_chinese(read_txt(corpus))))}        \n",
    "    return func_dict[str_range]\n",
    "\n",
    "#展开拼接字符组合\n",
    "def collate_char_iterator(itertools_perm):\n",
    "    return map(lambda x:\"\".join(x),itertools_perm)\n",
    "\n",
    "#字符生成器\n",
    "def chargen(language=\"lowercase\",n=1):\n",
    "    return collate_char_iterator(permutations(create_char_map(language),n))\n",
    "\n",
    "#编辑距离添加\n",
    "def add_char(input_char,language=\"lowercase\",n=2,forward=True):\n",
    "    return (\"{}{}\".format(char,input_char) \n",
    "        if forward==True else \"{}{}\".format(input_char,char) \n",
    "        for char in chargen(language=language,n=n))\n",
    "#编辑距离替换\n",
    "def replace_char(input_char,language=\"lowercase\",n=2):\n",
    "    m = len(input_char)\n",
    "    S = chargen(language=language,n=n)\n",
    "    for create_str in S:\n",
    "        for i in range(m):\n",
    "            result = yield input_char.replace(input_char[i:i+n],create_str)\n",
    "\n",
    "#批量字符串删除函数\n",
    "def delete_element(strings,symbles=symbles):\n",
    "    srcrep = {i:'' for i in symbles }\n",
    "    rep = dict((re.escape(k), v) for k, v in srcrep.items())\n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    return pattern.sub(lambda m: rep[re.escape(m.group(0))], strings)\n",
    "\n",
    "#编辑距离删除\n",
    "def delete_char(input_char,language=\"lowercase\",n=2):\n",
    "    return (delete_element(input_char,\"\".join(chars)) for chars in permutations(input_char,n))\n",
    "\n",
    "#编辑距离生成\n",
    "def translation_str(input_char,language=\"lowercase\",n=2):\n",
    "    del_ = delete_char(input_char,language=language,n=n)\n",
    "    replace_ = replace_char(input_char,language=language,n=n)\n",
    "    add_forward = add_char(input_char,language=language,n=n,forward=True)\n",
    "    add_backward = add_char(input_char,language=language,n=n,forward=False)\n",
    "    return tuple(list(del_)+list(replace_)+list(add_forward)+list(add_backward))\n",
    "\n",
    "#批量编辑距离生成\n",
    "def translation_n(input_char,language=\"lowercase\",n=2):\n",
    "    result = []\n",
    "    for i in range(1,n+1):\n",
    "        result += list(translation_str(input_char,language=language,n=i))\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "#拼写纠错模块\n",
    "@calltime\n",
    "def check_str(input_char,word_dict=False,error_dict=False):\n",
    "    prob_dict = dict()\n",
    "    if word_dict:\n",
    "        word_dict = word_dict\n",
    "    else:\n",
    "        word_dict = word_dict_func(corpus,log=False)\n",
    "    if input_char in word_dict:\n",
    "        check = filter(lambda word : len(word) > 0,translation_n(input_char,language=\"chinese\",n=1))\n",
    "        Pc = word_dict[input_char] \n",
    "        for sc_element in check:\n",
    "            if sc_element in error_dict:\n",
    "                Psc = error_dict[sc_element]\n",
    "                bayes_ = Psc*Pc\n",
    "                expr = { bayes_ : sc_element }\n",
    "                prob_dict.update(expr)\n",
    "        Eword = prob_dict[max(prob_dict)]\n",
    "        return {\"EM\":Eword,\"D\":prob_dict,\"C\":Pc,\"bayes\":bayes_}\n",
    "    return input_char\n",
    "    \n",
    "\n",
    "# 静态配置项\n",
    "corpus = \"/home/manman/Documents/相互转移/gitee项目/NLP数据集合/豆瓣电影数据集(2019.3)/豆瓣电影简介.txt\"\n",
    "dir_path = \"/home/manman/Documents/相互转移/gitee项目/NLP数据集合/词库/chinese/\"\n",
    "example_error = location_dict(dir_path)\n",
    "example_error\n",
    "word_dict = word_dict_func(corpus,log=False)\n",
    "\n",
    "# 测试运行\n",
    "test = check_str(\"上海\",word_dict,example_error)\n",
    "EMword , D , C , bayes = test[\"EM\"],test['D'],test['C'],test['bayes']\n",
    "EMword \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
